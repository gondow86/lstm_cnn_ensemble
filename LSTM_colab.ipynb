{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "3DZwQgubsMHX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import scipy\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeRqGHktsOBf",
        "outputId": "abb77b0e-3b42-4225-85e2-46eb72917b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "EAFpvz2TsT8E"
      },
      "outputs": [],
      "source": [
        "# # Hyper parameters\n",
        "# num_classes = 5\n",
        "# num_epochs = 10\n",
        "# batch_size = 64\n",
        "# # batch_size = 64\n",
        "# learning_rate = 0.01\n",
        "\n",
        "# segment_points = int(250 * (1667 / 2000)) # どれくらいで区切るか, ピークが1667点ごとくらいに現れる\n",
        "# sequence_length = segment_points * 5 # 例 1セグメントあたりのサンプル数 250Hz * 5s\n",
        "# overlap = int(sequence_length * 0.3)\n",
        "# input_size = 1 # 特徴量の種類？\n",
        "# hidden_size = 130 # 論文でいうhidden layerはこれ?\n",
        "# num_layers = 2 # Two-layered lstm?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyper parameters\n",
        "# 追加ver.\n",
        "num_classes = 5\n",
        "num_epochs = 500\n",
        "batch_size = 32\n",
        "# batch_size = 64\n",
        "learning_rate = 0.015\n",
        "\n",
        "segment_points = int(250 * (1667 / 2000)) # どれくらいで区切るか, ピークが1667点ごとくらいに現れる\n",
        "sequence_length = segment_points * 5 # 例 1セグメントあたりのサンプル数 250Hz * 5s\n",
        "overlap = int(sequence_length * 0.25)\n",
        "input_size = 1 # 特徴量の種類？\n",
        "hidden_size = 130 # 論文でいうhidden layerはこれ?\n",
        "num_layers = 2 # Two-layered lstm?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7hv5SKasack",
        "outputId": "5e6fce7c-3a3a-4b49-f8cc-8eb70e30aaae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/grpro/workspace/grad_thesis/lstm_cnn_ensemble\n",
            "CNN.ipynb   LSTM_colab.ipynb\t README.md  env\n",
            "LSTM.ipynb  LSTM_tutorial.ipynb  data\t    output.png\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "_cUKNjIKtDB-"
      },
      "outputs": [],
      "source": [
        "default_sample_rate = 2000\n",
        "down_sample_rate = 250\n",
        "ratio = default_sample_rate // down_sample_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OvebjSOsaYP",
        "outputId": "c68cb6ef-d1dd-40e2-e2b6-4a8a4cbe42c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "151899 1215199 168\n",
            "155587 1244699 172\n",
            "150337 1202699 167\n",
            "150768 1206149 167\n",
            "152524 1220199 169\n"
          ]
        }
      ],
      "source": [
        "# num_classes人分のdataframeを作る\n",
        "radar_frame_list = []\n",
        "scaler = MinMaxScaler((-1, 1)) # Min-Max Scaler -1~1\n",
        "\n",
        "for i in range(1, num_classes + 1):\n",
        "    wave_dem_2d = []\n",
        "    file_path = \"./data/radar_%02d.csv\" % i\n",
        "    radar_frame = pd.read_csv(file_path)\n",
        "    wave = radar_frame.to_numpy().flatten()\n",
        "    wave_dem = signal.decimate(wave, ratio)\n",
        "    for i in range(len(wave_dem)):\n",
        "      wave_dem_2d.append([wave_dem[i]])\n",
        "    # wave_dem_ts = torch.from_numpy(wave_dem.astype(np.float32)).clone() # tensorにする\n",
        "    print(i, len(wave), len(wave_dem_2d) // 900)\n",
        "\n",
        "    remaining = len(wave_dem_2d)\n",
        "    n = 0\n",
        "    n_stop = sequence_length\n",
        "    wave_segments = []\n",
        "\n",
        "    while n_stop < len(wave_dem_2d):\n",
        "        n_start = 0 + ((sequence_length - 1) - (overlap - 1)) * n\n",
        "        n_stop = n_start + sequence_length\n",
        "        tmp = []\n",
        "        wave_segments.append(scaler.fit_transform(wave_dem_2d[n_start:n_stop]))\n",
        "        n += 1\n",
        "    \n",
        "    radar_frame_list.append(wave_segments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.4311903 ],\n",
              "       [-0.397682  ],\n",
              "       [-0.36072063],\n",
              "       ...,\n",
              "       [-0.38272589],\n",
              "       [-0.38216714],\n",
              "       [-0.38215522]])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "radar_frame_list[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ems1EUFIga7b",
        "outputId": "82458429-97d8-4211-f9cf-682888d4c20e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(wave_dem_2d) # tensorにはしていない"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnD1kKfnf4is",
        "outputId": "b51fc966-4476-47ae-9c1c-feaf04557ea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-2.3435893667948337e-05"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wave_dem[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pic-ZwvTZi8X",
        "outputId": "e9352215-0aac-43ae-989d-76a8b0354912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-2.37119380e-05]\n",
            " [-2.38183832e-05]\n",
            " [-2.39258871e-05]\n",
            " ...\n",
            " [-7.11852346e-06]\n",
            " [-6.73462954e-06]\n",
            " [-6.34069284e-06]]\n"
          ]
        }
      ],
      "source": [
        "print(radar_frame.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1irmKjMtgTg",
        "outputId": "39c7fb2a-af6d-423d-a0a7-9d6d34e775ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = []\n",
        "for i in range(len(radar_frame_list)):\n",
        "    for j in range(len(radar_frame_list[i])):\n",
        "        labels.append(i + 1)\n",
        "\n",
        "labels_df = pd.Series(labels)\n",
        "torch.tensor(labels_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYkmvxNStn92",
        "outputId": "0ad8d1ff-2f1e-409c-be86-6f17241bd36f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "976 425\n",
            "780 1009\n",
            "587 578\n",
            "394 368\n",
            "194 580\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(radar_frame_list)\n",
        "tmp = df.to_numpy().flatten()\n",
        "df = pd.Series(tmp).dropna()\n",
        "tmp = df.to_numpy().flatten()\n",
        "\n",
        "tmp_labels = labels_df.to_numpy().flatten()\n",
        "for i in reversed(range(len(tmp))):\n",
        "  if len(tmp[i]) != sequence_length:\n",
        "    print(i, len(tmp[i]))\n",
        "    tmp = np.delete(tmp, i)\n",
        "    tmp_labels = np.delete(tmp_labels, i)\n",
        "\n",
        "df = pd.Series(tmp)\n",
        "labels_df = pd.Series(tmp_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QJOJGa4ZOAL",
        "outputId": "32087f9f-5c11-42ec-8777-cb8612fa3445"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0      [[-0.43119030027867716], [-0.39768199524563536...\n",
              " 1      [[-0.3534415565242706], [-0.35845964800756086]...\n",
              " 2      [[-0.18042866945988206], [-0.19453438296124625...\n",
              " 3      [[-0.6546532362142365], [-0.621911348400261], ...\n",
              " 4      [[0.6066640776486409], [0.636202403689861], [0...\n",
              "                              ...                        \n",
              " 967    [[0.2978653744735571], [0.2835063588966514], [...\n",
              " 968    [[-0.283224584578006], [-0.3079258528454299], ...\n",
              " 969    [[0.840542403153628], [0.8258411435483969], [0...\n",
              " 970    [[0.6445997743981384], [0.6645212646281974], [...\n",
              " 971    [[-0.6693811764847345], [-0.6616021006824988],...\n",
              " Length: 972, dtype: object,\n",
              " pandas.core.series.Series,\n",
              " numpy.ndarray,\n",
              " numpy.ndarray,\n",
              " numpy.float64,\n",
              " 1040)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df, type(df), type(df[0]), type(df[0][0]), type(df[0][0][0]), len(df[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns6jKMK0jlMO",
        "outputId": "2f10620e-152d-4ebc-8f2f-411d062d318d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "967    5\n",
              "968    5\n",
              "969    5\n",
              "970    5\n",
              "971    5\n",
              "Length: 972, dtype: int64"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "8ALujHuBt48l"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataset, labels, root_dir, transform=None) -> None:\n",
        "        # super().__init__()\n",
        "        self.radar_heartbeat = dataset\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "        # heartbeat_segment = torch.FloatTensor(self.radar_heartbeat[idx])\n",
        "        # subject_label = torch.LongTensor(self.labels[idx])\n",
        "        # if self.transform: # transform適用されず?\n",
        "        # heartbeat_segment = self.transform(self.radar_heartbeat[idx]) # tensorに\n",
        "        onehot_label = torch.eye(num_classes)[self.labels[idx] - 1] # one hot encording\n",
        "        # onehot_label = self.transform(self.labels[idx]) # tensorに\n",
        "\n",
        "        # return heartbeat_segment, subject_label\n",
        "        # return torch.from_numpy(self.radar_heartbeat.to_numpy().copy()), torch.tensor(labels_df)    \n",
        "        # return torch.stack(self.radar_heartbeat.to_numpy().tolist()), torch.tensor(labels_df)    \n",
        "        # return self.radar_heartbeat[idx], labels_df[idx]\n",
        "        return torch.tensor(self.radar_heartbeat[idx]), onehot_label\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.radar_heartbeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "NZ90ssVrvahI"
      },
      "outputs": [],
      "source": [
        "dataset = MyDataset(df, labels_df, \"./data/\", transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "-MY3ko2llOsV"
      },
      "outputs": [],
      "source": [
        "seg, lab = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ24_ehWml26",
        "outputId": "f388dded-0d1c-4362-f2d1-79f179885126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Tensor, 1040, tensor([1., 0., 0., 0., 0.]))"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(seg), len(seg), lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOtIGfVluDBe",
        "outputId": "e66a3611-44ce-441f-e29d-03a1ec4dedc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "full: 972 -> train: 777, test: 195\n"
          ]
        }
      ],
      "source": [
        "train_size = int(0.8 * len(df.values))\n",
        "test_size = len(df.values) - train_size\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "print(f\"full: {len(dataset)} -> train: {len(train_set)}, test: {len(test_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "KDkUwglxuHy4"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "cEr02Pd1uJya"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes) -> None:\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "    # print(x.size(), h0.size(), c0.size())\n",
        "    # out, _ = self.rnn(x, h0)\n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "    out = out[:, -1, :]\n",
        "\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "IDJNiVRAuLdH"
      },
      "outputs": [],
      "source": [
        "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVj9gCQnuMwa",
        "outputId": "2a417c7c-cb4e-43aa-f9f4-ae744ad75253"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_837/3942043653.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  signals = torch.tensor(signals)\n"
          ]
        }
      ],
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (signals, labels) in enumerate(train_loader):\n",
        "    signals = torch.tensor(signals)\n",
        "    signals = signals.float()\n",
        "    signals = signals.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # print(signals.size())\n",
        "    outputs = model(signals)\n",
        "    # print(outputs)\n",
        "    loss = criterion(outputs, labels) # will check the shapes of outputs and labels\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # if (i + 1) % 15 == 0:\n",
        "  print(f'Epoch [{epoch+1}/`{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19\n"
          ]
        }
      ],
      "source": [
        "print(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 / 32 = Acc: 46.875 %\n",
            "30 / 64 = Acc: 46.875 %\n",
            "42 / 96 = Acc: 43.75 %\n",
            "52 / 128 = Acc: 40.625 %\n",
            "55 / 145 = Acc: 37.93103448275862 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_837/3918647096.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  signals = torch.tensor(signals)\n",
            "/tmp/ipykernel_837/3918647096.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  outputs[j] = softmax(out)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  softmax = nn.Softmax()\n",
        "  for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
        "    signals = torch.tensor(signals)\n",
        "    signals = signals.float()\n",
        "    signals = signals.to(device)\n",
        "    one_hot_labels = one_hot_labels.to(device)\n",
        "    # print(len(one_hot_labels))\n",
        "    outputs = model(signals)\n",
        "    for j, out in enumerate(outputs):\n",
        "      outputs[j] = softmax(out)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
        "\n",
        "    n_samples += one_hot_labels.size(0) # add batch_size\n",
        "    # labels = [] # labels per batch size\n",
        "    for k, labels in enumerate(one_hot_labels):\n",
        "      # labels.append(torch.argmax(one_hot_labels[k]))\n",
        "      if predicted[k] == torch.argmax(labels):\n",
        "        # print(predicted[k], torch.argmax(labels[k]))\n",
        "        n_correct += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
        "    # print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([17])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.argmax(labels)\n",
        "labels.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 0, 0, 3, 1, 1, 2, 2, 1, 1, 2, 0, 0, 0], device='cuda:0'),\n",
              " tensor([0., 0., 0., 0., 1.], device='cuda:0'))"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted, (labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ True, False, False, False,  True,  True, False, False, False, False,\n",
              "         False, False, False, False,  True,  True,  True], device='cuda:0'),\n",
              " tensor(1., device='cuda:0'))"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = (predicted == torch.argmax(labels[len(labels)-1]))\n",
        "result, labels[len(labels)-1]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "509ebe440ff8829e001a14a6a100e0bf6e98d8654d4df1b14b1a4d7c455d9242"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
